{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Analysis - Module 4\n",
                "## Data Cleaning, Pre-Processing & Exploration\n",
                "\n",
                "**Your Role:** Data Analyst at a B2B SaaS Company\n",
                "\n",
                "**Your Mission:** Transform messy data into analysis-ready data.\n",
                "\n",
                "**Why this matters:**\n",
                "- Real-world data is NEVER clean\n",
                "- 80% of a data analyst's time is spent cleaning data\n",
                "- Bad data leads to bad decisions\n",
                "- Clean data = faster, more accurate analysis\n",
                "\n",
                "**This module covers:**\n",
                "- Finding and removing duplicates\n",
                "- Standardizing text data (case, whitespace)\n",
                "- Handling missing values (NaN)\n",
                "- Data type conversions\n",
                "- Splitting and combining columns\n",
                "- Dropping unnecessary data\n",
                "- Exploratory data analysis\n",
                "- Correlation and statistical analysis\n",
                "- Time series basics\n",
                "\n",
                "**Dataset files used:**\n",
                "- `customers_dirty.csv` - Messy data for cleaning\n",
                "- `TechFlow.csv` - Full dataset for exploration\n",
                "- `daily_metrics.csv` - Time series data\n",
                "\n",
                "**Time to complete:** ~90 minutes\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SETUP: Load Libraries and Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Standard imports\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Display options\n",
                "pd.set_option('display.max_columns', 15)\n",
                "pd.set_option('display.width', 200)\n",
                "pd.set_option('display.max_colwidth', 50)\n",
                "\n",
                "# Load datasets\n",
                "dirty = pd.read_csv('../dataset/customers_dirty.csv')\n",
                "df = pd.read_csv('../dataset/TechFlow.csv')\n",
                "daily = pd.read_csv('../dataset/daily_metrics.csv')\n",
                "\n",
                "print(\"Datasets loaded:\")\n",
                "print(f\"  dirty (messy data): {dirty.shape}\")\n",
                "print(f\"  df (clean data): {df.shape}\")\n",
                "print(f\"  daily (time series): {daily.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 1: First Look at Messy Data\n",
                "\n",
                "Always start by understanding what you're dealing with."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**View the messy data**\n",
                "\n",
                "```python\n",
                "dirty\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Identify the problems**\n",
                "\n",
                "```python\n",
                "# Get info about data types and nulls\n",
                "dirty.info()\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Common issues in this dataset:**\n",
                "1. **Duplicate rows** - Same customer appears multiple times\n",
                "2. **Inconsistent case** - TECHNOLOGY, technology, Technology\n",
                "3. **Extra whitespace** - \"  RetailHub  \" instead of \"RetailHub\"\n",
                "4. **Missing values** - Empty cells (Email, Phone, etc.)\n",
                "5. **Inconsistent formats** - Dates in different formats\n",
                "6. **Type issues** - Revenue as text with $, not numbers\n",
                "7. **Status inconsistency** - active, Active, ACTIVE"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 2: Dealing with Duplicates\n",
                "\n",
                "Duplicates can skew your analysis and cause double-counting."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.1 Finding Duplicates"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Check for exact duplicate rows**\n",
                "\n",
                "```python\n",
                "# Count duplicate rows\n",
                "print(f\"Total rows: {len(dirty)}\")\n",
                "print(f\"Duplicate rows: {dirty.duplicated().sum()}\")\n",
                "\n",
                "# Show the duplicates\n",
                "dirty[dirty.duplicated(keep=False)].sort_values('CustomerID')\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Check for duplicates on specific columns**\n",
                "\n",
                "```python\n",
                "# Duplicates based on CustomerID only\n",
                "print(f\"Duplicate CustomerIDs: {dirty.duplicated(subset=['CustomerID']).sum()}\")\n",
                "\n",
                "# Show them\n",
                "dirty[dirty.duplicated(subset=['CustomerID'], keep=False)].sort_values('CustomerID')\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.2 Removing Duplicates"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Drop exact duplicate rows**\n",
                "\n",
                "```python\n",
                "# Remove duplicates, keep first occurrence\n",
                "clean = dirty.drop_duplicates()\n",
                "\n",
                "print(f\"Before: {len(dirty)} rows\")\n",
                "print(f\"After: {len(clean)} rows\")\n",
                "print(f\"Removed: {len(dirty) - len(clean)} rows\")\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Drop duplicates based on key columns**\n",
                "\n",
                "```python\n",
                "# Keep only first occurrence of each CustomerID\n",
                "clean = dirty.drop_duplicates(subset=['CustomerID'], keep='first')\n",
                "\n",
                "print(f\"Before: {len(dirty)} rows\")\n",
                "print(f\"After: {len(clean)} rows\")\n",
                "print(f\"Unique customers: {clean['CustomerID'].nunique()}\")\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Options for keep parameter:**\n",
                "- `'first'` - Keep first occurrence (default)\n",
                "- `'last'` - Keep last occurrence  \n",
                "- `False` - Drop ALL duplicates"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 3: Standardizing Text Data\n",
                "\n",
                "Inconsistent text causes grouping and filtering problems."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.1 Case Standardization"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Check for case inconsistencies**\n",
                "\n",
                "```python\n",
                "# Look at Industry values\n",
                "print(\"Industry values (before):\")\n",
                "print(clean['Industry'].unique())\n",
                "\n",
                "# Count - these should be same category!\n",
                "print(\"\\nCounts (before):\")\n",
                "print(clean['Industry'].value_counts())\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Convert to consistent case**\n",
                "\n",
                "```python\n",
                "# Title case (first letter uppercase)\n",
                "clean['Industry'] = clean['Industry'].str.title()\n",
                "\n",
                "print(\"Industry values (after):\")\n",
                "print(clean['Industry'].value_counts())\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Common string case methods:**\n",
                "- `.str.lower()` - all lowercase\n",
                "- `.str.upper()` - ALL UPPERCASE\n",
                "- `.str.title()` - Title Case\n",
                "- `.str.capitalize()` - First letter only"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.2 Whitespace Cleaning"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Check for whitespace issues**\n",
                "\n",
                "```python\n",
                "# Look at CompanyName - notice leading/trailing spaces\n",
                "print(\"Company names (with quotes to show spaces):\")\n",
                "for name in clean['CompanyName'].head():\n",
                "    print(f\"'{name}'\")\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Strip whitespace**\n",
                "\n",
                "```python\n",
                "# Remove leading/trailing whitespace\n",
                "clean['CompanyName'] = clean['CompanyName'].str.strip()\n",
                "clean['Industry'] = clean['Industry'].str.strip()\n",
                "\n",
                "print(\"Company names (after strip):\")\n",
                "for name in clean['CompanyName'].head():\n",
                "    print(f\"'{name}'\")\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.3 Status Column Cleanup"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Standardize status values**\n",
                "\n",
                "```python\n",
                "# Check current values\n",
                "print(\"Status values (before):\")\n",
                "print(clean['Status'].value_counts())\n",
                "\n",
                "# Standardize to lowercase\n",
                "clean['Status'] = clean['Status'].str.lower().str.strip()\n",
                "\n",
                "print(\"\\nStatus values (after):\")\n",
                "print(clean['Status'].value_counts())\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 4: Data Type Conversions\n",
                "\n",
                "Numbers stored as text can't be used in calculations."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4.1 Cleaning Numeric Data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Check the Revenue column**\n",
                "\n",
                "```python\n",
                "# Revenue has $ signs - stored as text\n",
                "print(f\"Revenue dtype: {clean['Revenue'].dtype}\")\n",
                "print(\"\\nSample values:\")\n",
                "print(clean['Revenue'].head())\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Remove $ and convert to numeric**\n",
                "\n",
                "```python\n",
                "# Remove $ and convert to integer\n",
                "clean['Revenue'] = clean['Revenue'].str.replace('$', '', regex=False).str.replace(',', '', regex=False)\n",
                "clean['Revenue'] = pd.to_numeric(clean['Revenue'], errors='coerce')\n",
                "\n",
                "print(f\"Revenue dtype: {clean['Revenue'].dtype}\")\n",
                "print(f\"\\nRevenue stats:\")\n",
                "print(clean['Revenue'].describe())\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4.2 Converting Dates"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Check date formats**\n",
                "\n",
                "```python\n",
                "# Dates are in multiple formats!\n",
                "print(\"SignupDate samples:\")\n",
                "print(clean['SignupDate'].head(10))\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Convert to datetime**\n",
                "\n",
                "```python\n",
                "# pd.to_datetime is smart - handles multiple formats\n",
                "clean['SignupDate'] = pd.to_datetime(clean['SignupDate'], errors='coerce')\n",
                "\n",
                "print(f\"SignupDate dtype: {clean['SignupDate'].dtype}\")\n",
                "print(\"\\nConverted dates:\")\n",
                "print(clean['SignupDate'].head(10))\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Extract date components**\n",
                "\n",
                "```python\n",
                "# Create new columns from date\n",
                "clean['SignupYear'] = clean['SignupDate'].dt.year\n",
                "clean['SignupMonth'] = clean['SignupDate'].dt.month\n",
                "clean['SignupDayOfWeek'] = clean['SignupDate'].dt.day_name()\n",
                "\n",
                "clean[['CompanyName', 'SignupDate', 'SignupYear', 'SignupMonth', 'SignupDayOfWeek']].head()\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 5: Working with Missing Values (NaN)\n",
                "\n",
                "Missing data is common but must be handled carefully."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5.1 Finding Missing Values"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Count missing values per column**\n",
                "\n",
                "```python\n",
                "# Count NaN in each column\n",
                "print(\"Missing values per column:\")\n",
                "print(clean.isna().sum())\n",
                "\n",
                "print(\"\\nPercentage missing:\")\n",
                "print((clean.isna().sum() / len(clean) * 100).round(1))\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Find rows with missing values**\n",
                "\n",
                "```python\n",
                "# Rows with any missing value\n",
                "rows_with_missing = clean[clean.isna().any(axis=1)]\n",
                "\n",
                "print(f\"Rows with missing values: {len(rows_with_missing)}\")\n",
                "rows_with_missing\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5.2 Handling Missing Values"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Option 1: Fill with a value**\n",
                "\n",
                "```python\n",
                "# Fill missing emails with 'Unknown'\n",
                "clean['Email'] = clean['Email'].fillna('Unknown')\n",
                "\n",
                "# Fill missing phone with 'Not provided'\n",
                "clean['PhoneNumber'] = clean['PhoneNumber'].fillna('Not provided')\n",
                "\n",
                "print(\"After filling:\")\n",
                "print(clean[['Email', 'PhoneNumber']].head())\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Option 2: Fill with statistics**\n",
                "\n",
                "```python\n",
                "# For numeric columns, fill with mean or median\n",
                "# Example with full dataset\n",
                "print(f\"Revenue missing before: {clean['Revenue'].isna().sum()}\")\n",
                "\n",
                "# Fill with median (more robust to outliers)\n",
                "median_revenue = clean['Revenue'].median()\n",
                "clean['Revenue'] = clean['Revenue'].fillna(median_revenue)\n",
                "\n",
                "print(f\"Revenue missing after: {clean['Revenue'].isna().sum()}\")\n",
                "print(f\"Filled with median: {median_revenue}\")\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Option 3: Drop rows with missing values**\n",
                "\n",
                "```python\n",
                "# Drop rows where SignupDate is missing\n",
                "before = len(clean)\n",
                "clean = clean.dropna(subset=['SignupDate'])\n",
                "after = len(clean)\n",
                "\n",
                "print(f\"Dropped {before - after} rows with missing SignupDate\")\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**When to use each approach:**\n",
                "- **Fill with value** - When you have a sensible default\n",
                "- **Fill with mean/median** - For numeric data, preserves distribution\n",
                "- **Drop rows** - When data is critical and can't be estimated"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 6: Splitting and Combining Columns\n",
                "\n",
                "Sometimes data is too combined or too split."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6.1 Splitting Columns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Split Address into components**\n",
                "\n",
                "```python\n",
                "# View current address format\n",
                "print(\"Current Address format:\")\n",
                "print(clean['Address'].head())\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Extract email domain**\n",
                "\n",
                "```python\n",
                "# Split email on @ and get domain\n",
                "clean['EmailDomain'] = clean['Email'].str.split('@').str[-1]\n",
                "\n",
                "clean[['Email', 'EmailDomain']].head()\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6.2 Combining Columns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Create a full name column**\n",
                "\n",
                "```python\n",
                "# Combine CustomerID and CompanyName\n",
                "clean['CustomerLabel'] = clean['CustomerID'].astype(str) + ' - ' + clean['CompanyName']\n",
                "\n",
                "clean[['CustomerID', 'CompanyName', 'CustomerLabel']].head()\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 7: Dropping Unnecessary Data\n",
                "\n",
                "Remove columns and rows you don't need."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Drop columns**\n",
                "\n",
                "```python\n",
                "# Drop columns we don't need for analysis\n",
                "clean_final = clean.drop(columns=['PhoneNumber', 'Address', 'EmailDomain', 'CustomerLabel'])\n",
                "\n",
                "print(f\"Columns before: {len(clean.columns)}\")\n",
                "print(f\"Columns after: {len(clean_final.columns)}\")\n",
                "print(f\"\\nRemaining columns: {list(clean_final.columns)}\")\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Drop rows by condition**\n",
                "\n",
                "```python\n",
                "# Keep only active customers\n",
                "active_only = clean_final[clean_final['Status'] == 'active']\n",
                "\n",
                "print(f\"All customers: {len(clean_final)}\")\n",
                "print(f\"Active only: {len(active_only)}\")\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 8: Data Exploration with Clean Data\n",
                "\n",
                "Now let's explore the full TechFlow dataset."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8.1 Statistical Summary"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Describe numeric columns**\n",
                "\n",
                "```python\n",
                "# Full statistical summary\n",
                "df.describe()\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Include categorical columns**\n",
                "\n",
                "```python\n",
                "# Include object (text) columns\n",
                "df.describe(include='all')\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8.2 Distribution Analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Value counts for categories**\n",
                "\n",
                "```python\n",
                "# Distribution of subscription plans\n",
                "print(\"Subscription Plan Distribution:\")\n",
                "plan_counts = df['SubscriptionPlan'].value_counts()\n",
                "print(plan_counts)\n",
                "\n",
                "# As percentages\n",
                "print(\"\\nAs percentages:\")\n",
                "print(df['SubscriptionPlan'].value_counts(normalize=True).mul(100).round(1))\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Numeric distribution with binning**\n",
                "\n",
                "```python\n",
                "# Create revenue bins\n",
                "df['RevenueBin'] = pd.cut(\n",
                "    df['MonthlyRevenue'], \n",
                "    bins=[0, 100, 200, 500, 1000],\n",
                "    labels=['Low', 'Medium', 'High', 'Enterprise']\n",
                ")\n",
                "\n",
                "print(\"Revenue distribution:\")\n",
                "print(df['RevenueBin'].value_counts().sort_index())\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 9: Correlation Analysis\n",
                "\n",
                "Find relationships between variables."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Correlation matrix**\n",
                "\n",
                "```python\n",
                "# Select numeric columns\n",
                "numeric_cols = ['MonthlyRevenue', 'SeatCount', 'TenureMonths', 'AvgWeeklyLogins', \n",
                "                'NPS_Score', 'SupportTicketsRaised', 'Cancelled']\n",
                "\n",
                "# Calculate correlation\n",
                "correlation = df[numeric_cols].corr()\n",
                "correlation.round(2)\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Interpreting correlation:**\n",
                "- **+1** = Perfect positive (both increase together)\n",
                "- **0** = No relationship\n",
                "- **-1** = Perfect negative (one increases, other decreases)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Find strongest correlations with a target**\n",
                "\n",
                "```python\n",
                "# What correlates with cancellation?\n",
                "churn_corr = df[numeric_cols].corr()['Cancelled'].sort_values(ascending=False)\n",
                "\n",
                "print(\"Correlation with Cancellation:\")\n",
                "print(churn_corr)\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 10: Time Series Basics\n",
                "\n",
                "Analyze data over time."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10.1 Load and Prepare Time Series Data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**View daily metrics**\n",
                "\n",
                "```python\n",
                "# Convert Date to datetime\n",
                "daily['Date'] = pd.to_datetime(daily['Date'])\n",
                "\n",
                "daily.head(10)\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10.2 Time-Based Aggregations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Aggregate by week**\n",
                "\n",
                "```python\n",
                "# Set Date as index\n",
                "daily_indexed = daily.set_index('Date')\n",
                "\n",
                "# Weekly totals\n",
                "weekly = daily_indexed.groupby('CustomerID').resample('W').agg({\n",
                "    'Revenue': 'sum',\n",
                "    'Sessions': 'sum',\n",
                "    'Signups': 'sum'\n",
                "})\n",
                "\n",
                "weekly.head(10)\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Calculate daily changes**\n",
                "\n",
                "```python\n",
                "# For one customer\n",
                "customer_data = daily[daily['CustomerID'] == 1001].copy()\n",
                "\n",
                "# Calculate day-over-day change\n",
                "customer_data['Revenue_Change'] = customer_data['Revenue'].diff()\n",
                "customer_data['Revenue_Pct_Change'] = customer_data['Revenue'].pct_change() * 100\n",
                "\n",
                "customer_data[['Date', 'Revenue', 'Revenue_Change', 'Revenue_Pct_Change']].head(10)\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Rolling averages**\n",
                "\n",
                "```python\n",
                "# 5-day moving average\n",
                "customer_data['Revenue_MA5'] = customer_data['Revenue'].rolling(window=5).mean()\n",
                "\n",
                "customer_data[['Date', 'Revenue', 'Revenue_MA5']].head(10)\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ↓ Type the code below, then press Shift+Enter to run\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PRACTICE: Business Scenarios"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q1: Count duplicate CustomerIDs in the dirty data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your answer:\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q2: Standardize the Industry column to title case"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your answer:\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q3: Find all columns with missing values in TechFlow.csv"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your answer:\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q4: Calculate correlation between NPS_Score and MonthlyRevenue"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your answer:\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q5: Create age bins for TenureMonths (New: 0-6, Growing: 7-18, Mature: 19+)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your answer:\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q6: Calculate weekly revenue totals from daily_metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your answer:\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q7: Find all industries with more than one cancelled customer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your answer:\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# CHEAT SHEET\n",
                "\n",
                "## Duplicates\n",
                "```python\n",
                "df.duplicated().sum()                    # Count duplicates\n",
                "df[df.duplicated()]                      # Show duplicates\n",
                "df.drop_duplicates()                     # Remove duplicates\n",
                "df.drop_duplicates(subset=['col'])       # By column\n",
                "```\n",
                "\n",
                "## String Cleaning\n",
                "```python\n",
                "df['col'].str.lower()                    # lowercase\n",
                "df['col'].str.upper()                    # UPPERCASE\n",
                "df['col'].str.title()                    # Title Case\n",
                "df['col'].str.strip()                    # Remove whitespace\n",
                "df['col'].str.replace('old', 'new')      # Replace text\n",
                "df['col'].str.split('@').str[0]          # Split and select\n",
                "```\n",
                "\n",
                "## Type Conversion\n",
                "```python\n",
                "pd.to_numeric(df['col'], errors='coerce')    # To number\n",
                "pd.to_datetime(df['col'], errors='coerce')   # To date\n",
                "df['col'].astype(str)                        # To string\n",
                "df['col'].astype(int)                        # To integer\n",
                "```\n",
                "\n",
                "## Missing Values\n",
                "```python\n",
                "df.isna().sum()                          # Count NaN per column\n",
                "df[df['col'].isna()]                     # Rows with NaN\n",
                "df['col'].fillna(value)                  # Fill with value\n",
                "df['col'].fillna(df['col'].mean())       # Fill with mean\n",
                "df.dropna()                              # Drop rows with NaN\n",
                "df.dropna(subset=['col'])                # Drop if col is NaN\n",
                "```\n",
                "\n",
                "## Column Operations\n",
                "```python\n",
                "df.drop(columns=['col'])                 # Drop column\n",
                "df['new'] = df['a'] + df['b']            # Combine columns\n",
                "df['col'].str.split('-', expand=True)    # Split to columns\n",
                "pd.cut(df['col'], bins=[...])            # Create bins\n",
                "```\n",
                "\n",
                "## Exploration\n",
                "```python\n",
                "df.describe()                            # Statistics\n",
                "df['col'].value_counts()                 # Frequency\n",
                "df.corr()                                # Correlation matrix\n",
                "df[cols].corr()['target']                # Corr with target\n",
                "```\n",
                "\n",
                "## Time Series\n",
                "```python\n",
                "df['col'].diff()                         # Period change\n",
                "df['col'].pct_change()                   # % change\n",
                "df['col'].rolling(5).mean()              # Moving average\n",
                "df.resample('W').sum()                   # Weekly aggregate\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Module 4 Complete!\n",
                "\n",
                "**You now know how to:**\n",
                "- Find and remove duplicate rows\n",
                "- Standardize text data (case, whitespace)\n",
                "- Convert data types (numeric, dates)\n",
                "- Handle missing values (fill, drop)\n",
                "- Split and combine columns\n",
                "- Drop unnecessary data\n",
                "- Calculate correlations\n",
                "- Work with time series data\n",
                "\n",
                "**Key Takeaways:**\n",
                "1. Always explore data BEFORE cleaning\n",
                "2. 80% of analysis is data cleaning\n",
                "3. Use errors='coerce' to handle bad data gracefully\n",
                "4. Correlation does not imply causation\n",
                "5. Document your cleaning steps!\n",
                "\n",
                "**You have completed the Pandas Training Series!**"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}